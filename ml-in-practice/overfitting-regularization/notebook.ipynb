{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting & Regularization\n",
    "\n",
    "This notebook demonstrates overfitting with polynomial regression and how regularization (Ridge/Lasso) can help. We'll keep examples small and visual so beginners can see the effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create noisy nonlinear data\n",
    "X = np.linspace(-3, 3, 60).reshape(-1,1)\n",
    "y = np.sin(X).ravel() + np.random.normal(scale=0.2, size=X.shape[0])\n",
    "\n",
    "def fit_and_predict(degree, model):\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    Xp = poly.fit_transform(X)\n",
    "    model.fit(Xp, y)\n",
    "    yp = model.predict(Xp)\n",
    "    mse = mean_squared_error(y, yp)\n",
    "    return yp, mse\n",
    "\n",
    "# Fit degrees 1, 3, 9 with plain LinearRegression to show underfit -> good -> overfit\n",
    "yp1, mse1 = fit_and_predict(1, LinearRegression())\n",
    "yp3, mse3 = fit_and_predict(3, LinearRegression())\n",
    "yp9, mse9 = fit_and_predict(9, LinearRegression())\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(X, y, label='data', color='black', s=20)\n",
    "plt.plot(X, yp1, label=f'Degree 1 (MSE={mse1:.3f})')\n",
    "plt.plot(X, yp3, label=f'Degree 3 (MSE={mse3:.3f})')\n",
    "plt.plot(X, yp9, label=f'Degree 9 (MSE={mse9:.3f})')\n",
    "plt.legend()\n",
    "plt.title('Polynomial fits (underfit -> good -> overfit)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization example (Ridge & Lasso)\n",
    "We'll fit a flexible model (degree=9) and compare LinearRegression vs Ridge/Lasso to see how regularization reduces overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 9\n",
    "poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "Xp = poly.fit_transform(X)\n",
    "\n",
    "models = {\n",
    "    'Linear': LinearRegression(),\n",
    "    'Ridge (alpha=1)': Ridge(alpha=1.0),\n",
    "    'Lasso (alpha=0.01)': Lasso(alpha=0.01, max_iter=10000)\n",
    "}\n",
    "results = {}\n",
    "for name, m in models.items():\n",
    "    m.fit(Xp, y)\n",
    "    yp = m.predict(Xp)\n",
    "    results[name] = (yp, mean_squared_error(y, yp))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(X, y, color='black', s=20)\n",
    "for name, (yp, mse) in results.items():\n",
    "    plt.plot(X, yp, label=f\"{name} (MSE={mse:.3f})\")\n",
    "plt.legend()\n",
    "plt.title('Regularization reduces overfitting (degree=9)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
